{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Chapter 5: Advanced Labeling, Augmentation, and Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Introduction\n",
    "This chapter focuses on:\n",
    " - Techniques to reduce labeling cost\n",
    "- Methods to expand labeled datasets via augmentation\n",
    "- Domain-specific preprocessing, especially for time series data\n",
    "\n",
    "---\n",
    "## 2. Advanced Labeling\n",
    "Labeling is often the most expensive step in building a supervised learning system.\n",
    "Advanced labeling techniques allow us to label more data with fewer resources.\n",
    "\n",
    "---\n",
    "### 2.1 Semi-Supervised Labeling\n",
    "Combines a small set of labeled data with a large set of unlabeled data.\n",
    "Assumes similar data points in feature space belong to the same class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = datasets.make_classification(n_samples=200, n_features=2, n_classes=2, n_redundant=0)\n",
    "\n",
    "# Randomly unlabel some data\n",
    "rng = np.random.RandomState(42)\n",
    "y_missing = y.copy()\n",
    "unlabeled_indices = rng.rand(len(y)) < 0.8\n",
    "y_missing[unlabeled_indices] = -1\n",
    "\n",
    "# Apply label propagation\n",
    "lp_model = LabelPropagation()\n",
    "lp_model.fit(X, y_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " ### 2.2 Active Learning\n",
    " \n",
    "Uses sampling strategies to label the most informative examples first.\n",
    "Ideal when labeling budget is limited.\n",
    "\n",
    "---\n",
    "Margin Sampling (Illustration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Fit a model on a few initial labels\n",
    "initial_idx = np.where(y_missing != -1)[0][:10]\n",
    "model = SVC(kernel=\"linear\", probability=True)\n",
    "model.fit(X[initial_idx], y[initial_idx])\n",
    "\n",
    "# Predict margins for all points\n",
    "probs = model.predict_proba(X)\n",
    "margins = np.abs(probs[:, 0] - probs[:, 1])\n",
    "uncertain_idx = np.argsort(margins)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " ### 2.3 Weak Supervision with Snorkel\n",
    "\n",
    "Use labeling functions (heuristics) to assign noisy labels.\n",
    "\n",
    "A generative model is used to denoise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "@labeling_function()\n",
    "def lf_contains_my(x):\n",
    "    return 1 if \"my\" in x.text.lower() else -1\n",
    "\n",
    "@labeling_function()\n",
    "def lf_short_comment(x):\n",
    "    return 0 if len(x.text.split()) < 5 else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These labeling functions would be combined in Snorkel to generate weak labels.\n",
    "\n",
    "---\n",
    " ## 3. Data Augmentation\n",
    "Increase dataset size and diversity by generating valid variants of data points.\n",
    "\n",
    "---\n",
    "### Example: CIFAR-10 Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def augment(x, height, width, num_channels):\n",
    "    x = tf.image.resize_with_crop_or_pad(x, height + 8, width + 8)\n",
    "    x = tf.image.random_crop(x, [height, width, num_channels])\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example call (assuming `image` is a 32x32x3 tensor):\n",
    "image_aug = augment(image, 32, 32, 3)\n",
    "\n",
    "---\n",
    " Other augmentation strategies:\n",
    " - Semi-supervised augmentation\n",
    " - Unsupervised Data Augmentation (UDA)\n",
    " - Policy-based augmentation (e.g., AutoAugment)\n",
    "\n",
    "---\n",
    " ## 4. Time Series Preprocessing\n",
    " Common for forecasting problems, e.g., temperature prediction.\n",
    " Needs special handling for time order, windowing, sampling.\n",
    "\n",
    "---\n",
    " ### Seasonality Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.linspace(0, 10, 200)\n",
    "y = 3 * np.sin(2 * np.pi * x) + 15\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Seasonality in Time Series\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Windowing Strategy\n",
    "Generate input-output pairs using past data (e.g., 6-hour history -> 1-hour forecast)\n",
    "\n",
    "---\n",
    "#### Windowing illustration\n",
    "t = [t0, t1, ..., t5] -> predict t6\n",
    "or t = [t0 ... t23] -> predict t24\n",
    "\n",
    "---\n",
    "### Sampling Strategy\n",
    "Optimize training data size by sampling/aggregating at a suitable interval\n",
    "\n",
    "---\n",
    "For example, sampling once per hour instead of every 10 minutes reduces feature vector size from 792 to 126.\n",
    "\n",
    "---\n",
    "## 5. Conclusion\n",
    "Chapter 5 covered:\n",
    "- Labeling strategies: Semi-supervised, Active Learning, Weak Supervision\n",
    "- Data augmentation: Valid, label-preserving transformations\n",
    "- Time series preprocessing: Windowing, sampling, and seasonal patterns\n",
    "\n",
    "Techniques here improve data efficiency and model generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”‘ Keywords\n",
    "- Label Propagation\n",
    "- Semi-Supervised Labeling\n",
    "- Active Learning\n",
    "- Margin Sampling\n",
    "- Weak Supervision\n",
    "- Snorkel\n",
    "- Data Augmentation\n",
    "- CIFAR-10\n",
    "- Seasonality\n",
    "- Windowing\n",
    "- Sampling\n",
    "- Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
